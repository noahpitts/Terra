<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <!-- Title -->
        <title>terra</title>
        <meta name="description" content="Web App for Terra Project">
        <meta name="author" content="Noah Pitts">

        <!-- Favicon -->
        <link rel="icon" type="image/png" href="./icon/favicon.png">

        <!-- Fonts -->
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Source+Sans+Pro|Source+Serif+Pro" rel="stylesheet">

        <!-- CSS -->
        <link rel="stylesheet" href="./css/terra.css">

        <!-- JS -->

    </head>

    <body>
        <h1>Web App for Terra Project</h1>
        <h3>site under construction, please come back soon!!</h3>

        <h2>Abstact</h2>
        <p>Research in Artificial Intelligence and Machine Learning has entered a phase of rapid growth over the past decade and with the inclusion of abundant data sources and deep networks, new models are being proposed on the timespan of weeks rather than years. Until recently, machine learning goals were primarily focused on inference rather than the generation of data. However, with the inclusion of generative algorithms into the arsenal of AI technologies and the inevitable adoption of such techniques into the design professions, it becomes necessary to consider the role in which AI may affect the profession and the processes of design itself.</p>
        
        <p>A common ML paradigm would take a set of features, ùëã, and learn to produce a label, ùëå, describing those features. A generative network reverses this logic, taking in a label, ùëå, potentially random, and producing a set of features, ùëç,  that on the training limit is indistinguishable from a training dataset, while not from the dataset. The output of a generative model is an entirely synthetic creation with similar structure to the training data, based on the parameters tuned through a learning process. In 2014, Ian Goodfellow proposed the seminal model for Generative Adversarial Networks1 or GANs, a class of machine learning models that learns to create through the implementation of zero-sum game theory. In this paradigm, two networks are paired against each other, one acting as a generator for data samples, the other acting as a discriminator, probabilistically evaluating whether the generated sample is of the training data or is generated.</p>  
        
        <p>The invention of GANs has already begun to show significant promise in the generation of synthetic images trained on canonical ML training data2. However, at the present, there has been little application (at least published) of these tools to real world examples in the design professions such as architecture, either exploring the potentials for design exploration or for more directed design problem solving. The intent of this thesis is to implement a series of GANs3 to explore the relevance and potential for incorporation in to the future of design practice. While GANs are still in an extremely early area of research and development, I will be using them to ask fundamental questions of artificial architectural expression such as synthetic tectonics, phenomenology, and representation.</p>

        <h2>Research Questions</h2>
        <p>The overarching question is what role and potential capacity generative adversarial networks can play in the inclusion of artificial intelligence and machine learning in design.5 This question is intentionally framed to be exploratory and inductive rather than deductive. The intent is to frame the technology within the discourse of design theory rather than to attempt to solve a particular design problem.6 A list of initial sub questions, both theoretical and technical, are expressed below:</p>

        <ul>
            <li>What tools and frameworks are required to implement a GAN (tensorflow, keras, scikit-learn, etc.)? </li>
            <li>What data forms and structures (images, geometry, text) are able to be utilized with a GAN?</li>
            <li>What are some of the potential sources for training data (generated data and/or collected data)? </li>
            <li>What is the timescale for training a generative model and how does this scale with more complex types of data? </li>
            <li>What is the timescale for inference and sampling (after the model is trained) and how does this incorporate with other design applications? </li>
            <li>What forms of media are relevant to the inclusion of a generative model (CAD, VR/AR, Raster, Vector, etc)? </li>
            <li>What is an analogous framework for evaluating the application of a technology to a design theory (what are historical examples of how early technology has been brought into practice)? </li>
            <li>Given some clarification from previous questions, what are a set of case-studies/demos that can be implemented within a reasonable time while still providing validation of the model (either positive or negative)?</li>
            <li>What are the key metrics, if any, that can be used (or borrowed from core ML research) for validation and how are these appropriated into design theory. </li>
            <li>Given that the scope of this inquiry will be limited and using a posteriori methodology, what are the gaps in knowledge, and where are the areas and potential for further research?</li>
        </ul>
        
    </body>
</html>